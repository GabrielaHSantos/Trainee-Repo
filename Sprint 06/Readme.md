# Resumo

### Noções básicas de Analytics na AWS Parte 1 (Português)

Nos estudamos conceitos fundamentais de analytics e big data, incluindo os 5 Vs do big data (volume, variedade, velocidade, veracidade e valor) e seus desafios no processamento de grandes volumes de dados. Exploramos como a AWS oferece serviços abrangentes para analytics, como opções de armazenamento e transporte de dados para diferentes ambientes, bem como soluções disponíveis para cada tipo de processamento de dados. Aprendemos sobre o uso de ETL (Extract, Transform, Load) e ELT (Extract, Load, Transform) em pipelines de dados e as ferramentas AWS que suportam esses processos

### Noções básicas de Analytics na AWS Parte 2 (Português) 

Bom, nesta parte aprendemos sobre data lakes, seus benefícios, funções e os desafios enfrentados na sua criação, além dos serviços da AWS utilizados, como o AWS Lake Formation, que facilita o gerenciamento e a construção desses sistemas. Também exploramos as diferenças entre data lakes e data warehouses, destacando os desafios das soluções on-premises e as vantagens das opções oferecidas pela AWS. Estudamos os pilares da arquitetura de dados moderna, cenários de movimentação de dados e o conceito de malha de dados, juntamente com os benefícios e soluções da AWS aplicáveis. Por fim, identificamos os serviços e componentes necessários para criar arquiteturas de dados modernas, discutindo casos de uso comuns e exemplos práticos de aplicação em cenários reais.

### Serverless Analytics (Português)

Bom, neste curso aprendemos como conectar e processar dados de diversas formas e origens para tomar decisões orientadas por dados. Usamos ferramentas como AWS IoT Analytics, Amazon Cognito, AWS Lambda e Amazon SageMaker para agregar, processar, armazenar e disponibilizar dados. Precisei buscar informações por fora para entender melhor alguns conceitos, pois só o vídeo não foi suficiente, mas isso ajudou a compreender como essas ferramentas transformam dados brutos em informações úteis de forma prática e escalável.


### Introduction to Amazon Athena (Português)

Aqui fomos apresentados ao Amazon Athena, explorando como ele funciona e como é configurado dentro do ambiente da AWS. Durante a demonstração, aprendemos a criar um banco de dados no Console de Gerenciamento da AWS e a executar consultas SQL para validação. Como algumas partes do vídeo não ficaram totalmente claras, precisei complementar o aprendizado pesquisando mais sobre o tema, o que ajudou a entender como o Athena permite consultar dados no Amazon S3 de maneira prática e eficiente.

### AWS Glue Getting Started

Bom, neste curso, aprendemos os fundamentos do AWS Glue, começando pela sua arquitetura e casos de uso. Vimos como criar um bucket no Amazon S3 e carregar dados de exemplo, além de usar o AWS Glue para rastrear e catalogar dados. Também exploramos o AWS Glue Studio para realizar processos ETL (Extract, Transform, Load) e o AWS Glue DataBrew para carregar dados, criar jobs de perfil e trabalhar com projetos e receitas. O curso nos mostrou como usar o AWS Glue para automatizar e simplificar a manipulação de dados, ajudando a integrar e preparar dados de forma eficiente.

### Amazon EMR Getting Started

Bom, neste curso, aprendemos sobre o Amazon EMR, começando com a introdução à sua arquitetura e aos casos de uso, tanto na versão serverless quanto na versão com cluster. Vimos como criar recursos AWS para usar com o Amazon EMR Serverless, rodar jobs Spark e limpar os recursos após o uso. Também aprendemos a criar recursos AWS para o Amazon EMR tradicional, incluindo clusters EMR no EC2 e Amazon EMR Studio, além de configurar um workspace no EMR. Por fim, fizemos a execução de jobs Spark utilizando o notebook do Amazon EMR Studio e aprendemos como limpar os recursos ao final.

### Getting Started with Amazon Redshift

Neste curso, aprendemos a trabalhar com o Amazon Redshift, explorando sua arquitetura e os principais casos de uso. Vimos como configurar um cluster, conectá-lo ao Editor de Consultas v2 e utilizar visualizações materializadas para otimizar consultas de BI. Também aprendemos a automatizar tarefas complexas e repetitivas com procedimentos armazenados. Ao final, vimos como limpar os recursos para garantir a eficiência do ambiente.

### Best Practices for Data Warehousing with Amazon Redshift (Português)

Aqui aprendemos as melhores práticas para implementar um data warehouse usando o Amazon Redshift. Vimos como projetar tabelas, armazenar dados, aplicar técnicas de ingestão de dados e gerenciar workloads de forma eficiente. Também discutimos como o dimensionamento de nós e clusters afeta o desempenho do sistema e como aplicar essas configurações para otimizar o uso do Amazon Redshift. Através dos conceitos e práticas ensinadas, conseguimos entender como construir e gerenciar um data warehouse escalável e de alto desempenho com o Amazon Redshift.

### Amazon QuickSight - Getting Started

Neste curso, aprendemos os conceitos básicos do Amazon QuickSight, começando com sua arquitetura e principais casos de uso. Vimos como criar datasets e análises no QuickSight, além de personalizar visualmente a ferramenta usando temas. Também exploramos o processo de publicação de dashboards e como usar o QuickSight Q para fazer perguntas em linguagem natural. Por fim, aprendemos a desativar a versão de avaliação do QuickSight Enterprise + Q.

# Exercícios

[Exercício Lab Athena](../Sprint%206/Exercicios/exercicioathena.md)

[Exercicio Lambda](../Sprint%206/Exercicios/exerciciolambda.md)

# Evidências

Acesse as *`evidencias`* do exercicio clicando [aqui](../Sprint%206/Evidencias)

# Certificados

Acesse os certificados [aqui](../Sprint%206/Certificados) 
